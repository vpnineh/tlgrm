# Ù…Ø³ÛŒØ±: main.py

import asyncio
import aiohttp
from config import settings
from utils.file_handler import read_urls_from_file, load_keywords
from utils.logger_setup import setup_logger
from core.fetcher import fetch_and_normalize_content
from core.parser import analyze_content
from core.saver import prepare_output_dirs, save_configs_to_file, encode_and_save_base64, generate_readme

async def main():
    logger = setup_logger()
    logger.info("="*50)
    logger.info("Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ùˆ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ú©Ø§Ø± Ú©Ø±Ø¯")
    logger.info("="*50)

    # ... (Ø¨Ø®Ø´ Û± Ùˆ Û² Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) ...
    keywords = load_keywords(settings.KEYWORDS_FILE)
    if not keywords:
        logger.error("ÙØ§ÛŒÙ„ keywords.json ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…ØªÙˆÙ‚Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
        return
    
    plain_urls = read_urls_from_file(settings.PLAIN_CONTENT_URLS_FILE)
    base64_urls = read_urls_from_file(settings.BASE64_CONTENT_URLS_FILE)
    if not plain_urls and not base64_urls:
        logger.error("Ù‡ÛŒÚ† URL Ø§ÛŒ Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…ØªÙˆÙ‚Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
        return

    tasks = []
    async with aiohttp.ClientSession() as session:
        for url in plain_urls: tasks.append(fetch_and_normalize_content(session, url, False, logger))
        for url in base64_urls: tasks.append(fetch_and_normalize_content(session, url, True, logger))
        results = await asyncio.gather(*tasks)

    # ... (Ø¨Ø®Ø´ Û³ ØªØ­Ù„ÛŒÙ„ Ùˆ ØªØ¬Ù…ÛŒØ¹ Ù†ØªØ§ÛŒØ¬ Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) ...
    logger.info("--- Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ùˆ ØªØ¬Ù…ÛŒØ¹ Ù†ØªØ§ÛŒØ¬ ---")
    country_names = [k for k in keywords if k not in settings.PROTOCOL_CATEGORIES]
    final_protocol_configs = {p: set() for p in settings.PROTOCOL_CATEGORIES}
    final_country_configs = {c: set() for c in country_names}

    for url, content in results:
        if not content: continue
        
        analysis_result = analyze_content(content, keywords)
        stats = analysis_result['stats']
        
        if stats['total'] > 0:
            protocol_stats_str = ", ".join([f"{p}: {c}" for p, c in stats['protocols'].items()])
            logger.info(f"ğŸ“Š Ø¢Ù…Ø§Ø± Ø¨Ø±Ø§ÛŒ {url} -> Ú©Ù„: {stats['total']}, Ø§ÛŒØ±Ø§Ù†: {stats['iran_count']}, [{protocol_stats_str}]")
        
        for protocol, configs in analysis_result['protocol_configs'].items():
            final_protocol_configs[protocol].update(configs)
        for country, configs in analysis_result['country_configs'].items():
            final_country_configs[country].update(configs)

    # Û´. Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ (Ø¨Ø§ Ù…Ù†Ø·Ù‚ Ø¬Ø¯ÛŒØ¯)
    logger.info("--- Ø´Ø±ÙˆØ¹ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ ---")
    # Ù‡Ø± Ø¯Ùˆ Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø±Ø§ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    prepare_output_dirs([settings.OUTPUT_DIR, settings.BASE64_OUTPUT_DIR], logger)
    
    protocol_counts = {}
    for protocol, configs in final_protocol_configs.items():
        count = save_configs_to_file(settings.OUTPUT_DIR, protocol, configs, logger)
        if count > 0: protocol_counts[protocol] = count

    country_counts = {}
    for country, configs in final_country_configs.items():
        count = save_configs_to_file(settings.OUTPUT_DIR, country, configs, logger)
        if count > 0: country_counts[country] = count
        
        # *** ØªØºÛŒÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ: Ø³Ø§Ø®Øª ÙØ§ÛŒÙ„ Base64 Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ú©Ø´ÙˆØ±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ú©Ø§Ù†ÙÛŒÚ¯ Ø¯Ø§Ø±Ù†Ø¯ ***
        encode_and_save_base64(settings.BASE64_OUTPUT_DIR, country, configs, logger)


    # Ûµ. ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„ README.md
    logger.info("--- ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ ---")
    generate_readme(protocol_counts, country_counts, keywords, logger)

    logger.info("="*50)
    logger.info("ğŸ‰ ØªÙ…Ø§Ù… Ù…Ø±Ø§Ø­Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.")
    logger.info("="*50)

if __name__ == "__main__":
    asyncio.run(main())
